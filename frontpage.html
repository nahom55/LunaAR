<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <title>Markerless AR with A-Frame and AR.js</title>
    <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/c-frame/aframe-extras@7.5.0/dist/aframe-extras.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
    <link rel="stylesheet" href="style-front.css">
    <style>
    .hidden {
  visibility: hidden;
  display: none;
}
.overlay {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background-color: rgba(0, 0, 0,0);
  backdrop-filter: blur(4px);
  z-index: 100;
  transition: all 0.5s;
}
.modal {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  background-color: rgba(0,0,0,0.6);
  border: 1px solid #ccc;
  box-shadow: 0 4px 8px rgba(0,0,0,0.2);
  width: 300px;
  padding: 15px;
  z-index: 10000;
  border-radius: 8px;
  font-family: sans-serif;
  animation: slideIn 0.3s ease-out;
  background-color: rgb(21, 38, 54);
  border: none;
}
h2 {
  color: #ccc;
  text-align: center;
}
.pop-up {
  width: 18rem;
  padding-left: 0;
  margin-left: 0rem;
  padding-right: 0;
  font-size: 0.4rem;
  background-color: rgb(21, 38, 54);
}
.btnpop {
  width: 13rem;
  margin-left: 3rem;
  margin-top: 0.4rem;
  background-color: blue;
  color: white;
  border-radius: 15px;
  height: 2rem;
  border: none;
}
.video-icon {
  background-color: blue; /* Bootstrap blue */
  color: white;
  border-radius: 50%;
  padding: 10px;
  font-size: 10px;
  margin-right: 10px;
}
    </style>
  </head>
  <body style="margin: 0; overflow: hidden;">
    <!-- Hamburger Menu -->
    <div id="nav-menu">
      <a href=''>Home</a>
      <a href='new-wifi.html'>Setup wifi</a>
      <a href='devices.html'>Devices</a>
    </div>
    <!-- Initial Description Text -->
    <div id="initial-description"><div id="hamburger-menu">
      <i class="fas fa-bars"></i>
    </div>
    </div>
    <!-- A-Frame Scene with AR.js -->

    <div class="modal hidden">
      <!-- <button type="button" class="btn--close-modal">&times;</button> -->
      <div class="pop-up">
        <h2> <i class="fas fa-video video-icon"></i>qemsha.com wants to use <br> your screen</h2>
        <button class="btnpop" type="button">Allow while visiting the site</button>
        <button class="btnpop" type="button">Allow this time</button>
        <button class="btnpop" type="button">Never Allow</button>
      </div>
    </div>
    <div class="overlay hidden"></div>

    <a-scene
      embedded
      arjs="sourceType: image; sourceUrl: bbck.png; debugUIEnabled: false; trackingMethod: best;"
      renderer="logarithmicDepthBuffer: true; colorManagement: true, exposure: 1.0; toneMapping: ACESFilmic;"
      vr-mode-ui="enabled: false"
    >

      <!-- Add a 3D Human Model -->
      <a-entity
        id="human-model"
        gltf-model="url(test-anm.glb)"
        scale="0.019 0.019 0.019"
        position="0 -1.03 -1"
        animation-mixer="clip: *; timeScale: 0; loop: repeat" 
        visible="false" <!-- Initially hidden -->
      ></a-entity>

      <!-- AR Buttons -->
      <a-entity id="serviceButtons" visible="false">
        <!-- Buttons will be added here -->
      </a-entity>

      <!-- Audio Element -->
      <a-entity id="audioElement" sound="src: url(kid.mp3); autoplay: false;"></a-entity>

      <!-- Camera with cursor for interactions -->
      <a-entity camera look-controls>
        <a-cursor fuse="true" fuse-timeout="500" geometry="primitive: ring; radiusInner: 0; radiusOuter: 0"></a-cursor>
      </a-entity>
    </a-scene>

    <!-- Green background plane with buttons -->
    <footer>
      <div class="input-area">
        <button class="mic-button"><i class="fas fa-microphone"></i></button>
        <button class="video-button"><i class="fas fa-video"></i></button>
        <input type="text" placeholder="Type something" id="textInput">
        <button class="send-button" id="startButton"><i class="fas fa-paper-plane"></i></button>
      </div>
    </footer>

    <script>
      const openModal = document.querySelector(".video-button");
      const modal = document.querySelector(".modal");
      const overlay = document.querySelector(".overlay");
      
      openModal.addEventListener("click", openmodalfun)
      overlay.addEventListener("click", closemodalfun)
      
      function openmodalfun() {
        modal.classList.remove("hidden");
        overlay.classList.remove("hidden");
      }
      function closemodalfun() {
        modal.classList.add("hidden");
        overlay.classList.add("hidden");
      }

      const startButton = document.getElementById("startButton");
      const screenSharingVideo = document.getElementById("screenSharingVideo"); // Add this if not already in HTML

      let cameraStream = null;

      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        alert("Camera access is not supported by your browser.");
      } else {
        startButton.addEventListener("click", startCamera);
      }





// Get all the modal buttons
const modalButtons = document.querySelectorAll('.btnpop');

// Add click event to each button
modalButtons.forEach(button => {
  button.addEventListener('click', closemodalfun);
});






      function startCamera() {
        navigator.mediaDevices
          .getUserMedia({ video: true, audio: false }) // You can enable audio if needed
          .then((stream) => {
            cameraStream = stream;
            screenSharingVideo.srcObject = stream;

            startButton.disabled = true;

            stream.getVideoTracks()[0].addEventListener("ended", () => {
              stopCamera();
            });
          })
          .catch((error) => {
            console.error("Error accessing the camera:", error);
          });
      }

      function stopCamera() {
        if (cameraStream) {
          cameraStream.getTracks().forEach((track) => track.stop());
          cameraStream = null;
          screenSharingVideo.srcObject = null;
          startButton.disabled = false;
        }
      }

      const micButton = document.querySelector('.mic-button');
      const textInput = document.getElementById('textInput');
      const responseArea = document.querySelector('.response-area');
      const sendButton = document.querySelector('.send-button');
      const RASA_API_URL = "https://34.229.142.15/webhooks/rest/webhook";
      let recognition;
      let transcript;
      let textValue;

      // Add click event listener for send button
      sendButton.addEventListener('click', function() {
        // window.location.href = "https://nahom55.github.io/LunaAR/new-wifi-index.html";
      });

      // Check if the browser supports the Web Speech API
      if ('webkitSpeechRecognition' in window) {
        const recognition = new webkitSpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = 'en-US';

        recognition.onstart = function() {
          micButton.classList.add('active');
          micButton.style.backgroundColor = 'red';
          textInput.placeholder = "Listening...";
        };

        recognition.onresult = async function(event) {
          transcript = event.results[0][0].transcript;
          textInput.value = transcript;
          textValue = transcript;
          textInput.placeholder = "Type something";
          console.log(textValue);

          if (textValue == "Wi-Fi." || textValue == "Devices." || textValue == "Front.") {
            localStorage.setItem("page", textValue);
            window.parent.postMessage({ key: "page", value: textValue }, "*");
            console.log("from local storage: ", localStorage.getItem("page"));
          }

          // sendMessageToRasa(transcript);
        };

        recognition.onerror = function(event) {
          console.error('Speech recognition error', event.error);
          textInput.placeholder = "Error occurred. Please try again.";
        };

        recognition.onend = function() {
          micButton.classList.remove('active');
          micButton.style.backgroundColor = '#4CAF50';
          textInput.placeholder = "Type something";
        };

        micButton.addEventListener('click', function() {
          recognition.start();
        });
      } else {
        micButton.disabled = true;
        textInput.placeholder = 'Voice input not supported';
      }

      async function sendMessageToRasa(message) {
        // Your existing RASA message handling code
      }

      function setupWiFi() {
        window.location.href = "https://wifi.qemsha.com";
      }
    
      function troubleshootInternet() {
        window.location.href = "https://apn.qemsha.com";
      }
      
      function devices() {
        window.location.href = "https://devices.qemsha.com";
      }
    
      function sayGoodbye() {
        console.log("Goodbye! Have a great day!");
      }

      const hamburgerMenu = document.getElementById("hamburger-menu");
      const navMenu = document.getElementById("nav-menu");

      navMenu.addEventListener("click", function(e) {
        clicker(e);
      });
      
      function clicker(e) {
        e.preventDefault();
        const btn = e.target.textContent;
        if (btn == "Home") {
          window.location.href = "https://home.qemsha.com";
        }
        if (btn == "Devices") {
          window.location.href = "https://devices.qemsha.com";
        }
        if (btn == "Setup wifi") {
          window.location.href = "https://wifi.qemsha.com";
        }
      }
      
      hamburgerMenu.addEventListener("click", () => {
        navMenu.style.display = navMenu.style.display === "block" ? "none" : "block";
      });
      
      function playAudio() {
        const audioElement = document.getElementById("audioElement");
        audioElement.components.sound.playSound();
      }
 
      // Function to load lip-sync data from JSON file
      async function loadLipSyncData() {
        try {
          const response = await fetch('output.json');
          if (!response.ok) throw new Error('Failed to load lip-sync data');
          return await response.json();
        } catch (error) {
          console.error('Error loading lip-sync data:', error);
          return null;
        }
      }

      // Map Rhubarb visemes to Oculus Viseme IDs
      const rhubarbToOculusViseme = {
        A: 10, // aa
        B: 0,  // sil
        C: 7,  // SS
        D: 4,  // DD
        E: 11, // E
        F: 5,  // FF
        G: 6,  // CH
        H: 10, // aa
        X: 0,  // sil
      };

      // Map Oculus Visemes to blend shapes
      const visemeToBlendShape = {
        0: 'viseme_sil', // sil
        1: 'viseme_PP',  // PP
        2: 'viseme_FF',  // FF
        3: 'viseme_TH',  // TH
        4: 'viseme_DD',  // DD
        5: 'viseme_kk',  // kk
        6: 'viseme_CH',  // CH
        7: 'viseme_SS',  // SS
        8: 'viseme_nn',  // nn
        9: 'viseme_RR',  // RR
        10: 'viseme_aa', // aa
        11: 'viseme_E',  // E
        12: 'viseme_ih', // ih
        13: 'viseme_oh', // oh
        14: 'viseme_ou', // ou
      };

      // Function to animate the character's mouth
      function animateCharacterMouth(visemeId) {
        const visemeName = visemeToBlendShape[visemeId];
        console.log(`Animating viseme: ${visemeName}`);

        const humanModel = document.getElementById("human-model");
        humanModel.object3D.traverse((child) => {
          if (child.isMesh && child.morphTargetInfluences) {
            const morphTargetDictionary = child.morphTargetDictionary;

            // Reset all blend shapes to 0
            for (let i = 0; i < child.morphTargetInfluences.length; i++) {
              child.morphTargetInfluences[i] = 0;
            }

            // Apply the current viseme
            if (morphTargetDictionary && visemeName && morphTargetDictionary[visemeName] !== undefined) {
              child.morphTargetInfluences[morphTargetDictionary[visemeName]] = 1;
            }
          }
        });
      }

      // Modified function to start lip-sync animation
      async function startLipSyncAnimation() {
        const lipSyncData = await loadLipSyncData();
        if (!lipSyncData) {
          console.error('Could not load lip-sync data');
          return;
        }

        const audioElement = document.getElementById("audioElement");

        lipSyncData.mouthCues.forEach((cue) => {
          setTimeout(() => {
            const visemeId = rhubarbToOculusViseme[cue.value];
            animateCharacterMouth(visemeId);
          }, cue.start * 1000);
        });

        audioElement.components.sound.playSound();
      }

      // Show the 3D model, start animation, and play audio after 4 seconds
      setTimeout(async () => {
        const humanModel = document.getElementById("human-model");
        humanModel.setAttribute("visible", true);
        humanModel.setAttribute("animation-mixer", "timeScale: 1");
        await startLipSyncAnimation();
      }, 2000);

      // Better version that waits for voices to load
      function textToSpeech(message) {
        if (!window.speechSynthesis) {
          console.error("Speech synthesis not supported in this browser.");
          return null;
        }

        function speak() {
          const voices = window.speechSynthesis.getVoices();

          // Try to find a known female English voice
          const femaleVoice = voices.find(voice =>
            voice.name.toLowerCase().includes("zira") || // MS Zira (Windows)
            voice.name.toLowerCase().includes("susan") || // Google Susan
            voice.name.toLowerCase().includes("female") ||
            voice.name.toLowerCase().includes("woman") ||
            (voice.lang === "en-US" && voice.name.toLowerCase().includes("english")) ||
            (voice.lang === "en-US" && voice.name.toLowerCase().includes("us"))
          ) || voices.find(voice => voice.lang === "en-US") || voices[0]; // Fallbacks

          const utterance = new SpeechSynthesisUtterance(message);
          utterance.voice = femaleVoice;
          window.speechSynthesis.speak(utterance);
          return utterance;
        }

        // If voices aren't loaded yet, wait for them to load first
        if (window.speechSynthesis.getVoices().length === 0) {
          window.speechSynthesis.onvoiceschanged = speak;
        } else {
          return speak();
        }
      }
 
      // Eye blinking functionality
      function animateEyes() {
        const humanModel = document.getElementById("human-model");
        humanModel.object3D.traverse((child) => {
          if (child.isMesh && child.morphTargetInfluences) {
            const morphTargetDictionary = child.morphTargetDictionary;

            if (morphTargetDictionary && morphTargetDictionary['eyeBlinkLeft'] !== undefined) {
              child.morphTargetInfluences[morphTargetDictionary['eyeBlinkLeft']] = 1;
              child.morphTargetInfluences[morphTargetDictionary['eyeBlinkRight']] = 1;
            }
          }
        });

        setTimeout(() => {
          humanModel.object3D.traverse((child) => {
            if (child.isMesh && child.morphTargetInfluences) {
              const morphTargetDictionary = child.morphTargetDictionary;

              if (morphTargetDictionary && morphTargetDictionary['eyeBlinkLeft'] !== undefined) {
                child.morphTargetInfluences[morphTargetDictionary['eyeBlinkLeft']] = 0;
                child.morphTargetInfluences[morphTargetDictionary['eyeBlinkRight']] = 0;
              }
            }
          });
        }, 200);
      }

      // Start periodic blinking
      setInterval(() => {
        animateEyes();
      }, 4000);
    </script>
  </body>
</html>
